{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization of LightGBM with Focal Loss\n",
    "\n",
    "Here I will quicky show how to use [Hyperopt](https://github.com/hyperopt/hyperopt) to optimize all LightGBM's hyperparameters and $\\alpha$ and $\\gamma$ for the Focal Loss. \n",
    "\n",
    "I am going to assume that we want to optimise \"against\" a standard metric for imbalanced datasets such as the F1 score\n",
    "\n",
    "We first need to code that metric to be passed to LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.misc import derivative\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "\n",
    "def sigmoid(x): return 1./(1. +  np.exp(-x))\n",
    "\n",
    "def focal_loss_lgb(y_pred, dtrain, alpha, gamma):\n",
    "    \"\"\"\n",
    "    Focal Loss for lightgbm\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_pred: numpy.ndarray\n",
    "        array with the predictions\n",
    "    dtrain: lightgbm.Dataset\n",
    "    alpha, gamma: float\n",
    "        See original paper https://arxiv.org/pdf/1708.02002.pdf\n",
    "    \"\"\"\n",
    "    a,g = alpha, gamma\n",
    "    y_true = dtrain.label\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    return grad, hess\n",
    "\n",
    "def lgb_focal_f1_score(preds, lgbDataset):\n",
    "    \"\"\"\n",
    "    When using custom losses the row prediction needs to passed through a\n",
    "    sigmoid to represent a probability\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    preds: numpy.ndarray\n",
    "        array with the predictions\n",
    "    lgbDataset: lightgbm.Dataset\n",
    "    \"\"\"\n",
    "    preds = sigmoid(preds)\n",
    "    binary_preds = [int(p>0.5) for p in preds]\n",
    "    y_true = lgbDataset.get_label()\n",
    "    return 'f1', f1_score(y_true, binary_preds), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    objective function for lightgbm.\n",
    "    \"\"\"\n",
    "    # hyperopt casts as float\n",
    "    params['num_boost_round'] = int(params['num_boost_round'])\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "\n",
    "    # need to be passed as parameter\n",
    "    params['verbose'] = -1\n",
    "    params['seed'] = 1\n",
    "\n",
    "    focal_loss = lambda x,y: focal_loss_lgb(x, y,\n",
    "        params['alpha'], params['gamma'])\n",
    "    # if you do not want an annoying warning related to the unrecognised param\n",
    "    # 'alpha', simple pop them out from the dict params here and insert them\n",
    "    # back before return. For this particular notebook I can live  with it, so\n",
    "    # I will leave it\n",
    "    cv_result = lgb.cv(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=params['num_boost_round'],\n",
    "        fobj = focal_loss,\n",
    "        feval = lgb_focal_f1_score,\n",
    "        nfold=3,\n",
    "        stratified=True,\n",
    "        early_stopping_rounds=20)\n",
    "    # I save the length or the results (i.e. the number of estimators) because\n",
    "    # it might have stopped earlier and is always useful to have that\n",
    "    # information \n",
    "    early_stop_dict[objective.i] = len(cv_result['f1-mean'])\n",
    "    score = round(cv_result['f1-mean'][-1], 4)\n",
    "    objective.i+=1\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the parameter space that we are going to be exploring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'num_boost_round': hp.quniform('num_boost_round', 50, 500, 20),\n",
    "    'num_leaves': hp.quniform('num_leaves', 31, 255, 4),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.1, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.01, 0.1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 0.1),\n",
    "    'alpha': hp.uniform('alpha', 0.1, 0.75),\n",
    "    'gamma': hp.uniform('gamma', 0.5, 5)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are ready, let's just load some data and run the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>education_occupation</th>\n",
       "      <th>native_country_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>0.095890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12914</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>0.205479</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass  education  marital_status  occupation  \\\n",
       "11961  0.287671          0          0               0           0   \n",
       "1230   0.095890          1          1               0           1   \n",
       "16067  0.589041          1          1               1           1   \n",
       "12914  0.452055          1          1               2           2   \n",
       "6343   0.205479          1          2               2           3   \n",
       "\n",
       "       relationship  race  gender  capital_gain  capital_loss  hours_per_week  \\\n",
       "11961             0     0       0           0.0           0.0        0.397959   \n",
       "1230              0     0       1           0.0           0.0        0.397959   \n",
       "16067             1     0       1           0.0           0.0        0.193878   \n",
       "12914             2     0       0           0.0           0.0        0.479592   \n",
       "6343              2     0       0           0.0           0.0        0.397959   \n",
       "\n",
       "       native_country  education_occupation  native_country_occupation  \n",
       "11961               0                     0                          0  \n",
       "1230                0                     1                          1  \n",
       "16067               0                     1                          1  \n",
       "12914               0                     2                          2  \n",
       "6343                0                     3                          3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"../data/\")\n",
    "databunch = pickle.load(open(PATH/'adult_databunch.p', 'rb'))\n",
    "colnames = databunch.colnames\n",
    "categorical_columns = databunch.categorical_columns + databunch.crossed_columns\n",
    "X = databunch.data\n",
    "y = databunch.target\n",
    "# you know, in real life, train, valid AND test, and you keep it somewhere safe...\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.25,\n",
    "    random_state=1, stratify=y)\n",
    "# let's have a look:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb.Dataset(\n",
    "    X_tr, y_tr,\n",
    "    feature_name=colnames,\n",
    "    categorical_feature = categorical_columns,\n",
    "    free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:25<01:40, 25.01s/it, best loss: -0.481]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:34<01:00, 20.32s/it, best loss: -0.7066]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:52<00:39, 19.54s/it, best loss: -0.7066]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [01:24<00:23, 23.33s/it, best loss: -0.7066]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:430: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:35<00:00, 19.63s/it, best loss: -0.7066]\n"
     ]
    }
   ],
   "source": [
    "# the error bar looks better in the terminal...\n",
    "objective.i=0\n",
    "trials = Trials()\n",
    "early_stop_dict = {}\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=5,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** using the fscore (or any score) is normally more expensive than a loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "best['num_boost_round'] = early_stop_dict[trials.best_trial['tid']]\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['verbose'] = -1\n",
    "focal_loss = lambda x,y: focal_loss_lgb(x, y, best['alpha'], best['gamma'])\n",
    "model = lgb.train(best, train, fobj=focal_loss)\n",
    "preds = model.predict(X_val)\n",
    "preds = sigmoid(preds)\n",
    "preds = (preds > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7121898206846586\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_val, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
